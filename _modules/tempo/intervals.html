<!doctype html>
<html class="no-js">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><link rel="index" title="Index" href="../../genindex.html" /><link rel="search" title="Search" href="../../search.html" />

    <link rel="shortcut icon" href="../../_static/favicon.svg"/><meta name="generator" content="sphinx-4.5.0, furo 2022.09.29"/>
        <title>tempo.intervals - Tempo 0.1.22 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo.css?digest=d81277517bee4d6b0349d71bb2661d4890b5617c" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo-extensions.css?digest=30d1aed668e5c3a91c3e3bf6a60b675221979f0e" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  --color-brand-primary: #7C4DFF;
  --color-brand-content: #7C4DFF;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  --color-brand-primary: #7C4DFF;
  --color-brand-content: #7C4DFF;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  --color-brand-primary: #7C4DFF;
  --color-brand-content: #7C4DFF;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../../index.html"><div class="brand">Tempo 0.1.22 documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon no-toc" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../../index.html">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo only-light" src="../../_static/tempo - light background.svg" alt="Light Logo"/>
    <img class="sidebar-logo only-dark" src="../../_static/tempo - dark background.svg" alt="Dark Logo"/>
  </div>
  
  <span class="sidebar-brand-text">Tempo 0.1.22 documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="../../search.html" role="search">
  <input class="sidebar-search" placeholder=Search name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul>
<li class="toctree-l1"><a class="reference external" href="https://databricks.com/learn/labs">Databricks Labs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../user-guide.html">User Guide</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../reference/index.html">API Reference</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../reference/tempo.tsdf.html">tempo.tsdf</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/tempo.intervals.html">tempo.intervals</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../contributing.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tempo-team.html">Tempo Team</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../future-roadmap.html">Future Roadmap</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon no-toc" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <h1>Source code for tempo.intervals</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">cached_property</span>

<span class="kn">from</span> <span class="nn">pyspark.sql.dataframe</span> <span class="kn">import</span> <span class="n">DataFrame</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="n">NumericType</span><span class="p">,</span> <span class="n">BooleanType</span><span class="p">,</span> <span class="n">StructField</span>
<span class="kn">import</span> <span class="nn">pyspark.sql.functions</span> <span class="k">as</span> <span class="nn">f</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.window</span> <span class="kn">import</span> <span class="n">Window</span>


<span class="k">def</span> <span class="nf">is_metric_col</span><span class="p">(</span><span class="n">col</span><span class="p">:</span> <span class="n">StructField</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
    <span class="k">return</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">col</span><span class="o">.</span><span class="n">dataType</span><span class="p">,</span> <span class="n">NumericType</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span>
        <span class="n">col</span><span class="o">.</span><span class="n">dataType</span><span class="p">,</span> <span class="n">BooleanType</span>
    <span class="p">)</span>


<div class="viewcode-block" id="IntervalsDF"><a class="viewcode-back" href="../../reference/tempo.intervals.html#tempo.intervals.IntervalsDF">[docs]</a><span class="k">class</span> <span class="nc">IntervalsDF</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This object is the main wrapper over a `Spark DataFrame`_ which allows a</span>
<span class="sd">    user to parallelize computations over snapshots of metrics for intervals</span>
<span class="sd">    of time defined by a start and end timestamp and various dimensions.</span>

<span class="sd">    The required dimensions are `series` (list of columns by which to</span>
<span class="sd">    summarize), `metrics` (list of columns to analyze), `start_ts` (timestamp</span>
<span class="sd">    column), and `end_ts` (timestamp column). `start_ts` and `end_ts` can be</span>
<span class="sd">    epoch or TimestampType.</span>

<span class="sd">    .. _`Spark DataFrame`: https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.html</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">df</span><span class="p">:</span> <span class="n">DataFrame</span><span class="p">,</span> <span class="n">start_ts</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">end_ts</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">series_ids</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">         Constructor for :class:`IntervalsDF`.</span>

<span class="sd">        :param df:</span>
<span class="sd">        :type df: `DataFrame`_</span>
<span class="sd">        :param start_ts:</span>
<span class="sd">        :type start_ts: str</span>
<span class="sd">        :param end_ts:</span>
<span class="sd">        :type end_ts: str</span>
<span class="sd">        :param series_ids:</span>
<span class="sd">        :type series_ids: list[str]</span>
<span class="sd">        :rtype: None</span>

<span class="sd">        :Example:</span>

<span class="sd">        .. code-block:</span>

<span class="sd">            df = spark.createDataFrame(</span>
<span class="sd">                [[&quot;2020-08-01 00:00:09&quot;, &quot;2020-08-01 00:00:14&quot;, &quot;v1&quot;, 5, 0]],</span>
<span class="sd">                &quot;start_ts STRING, end_ts STRING, series_1 STRING, metric_1 INT, metric_2 INT&quot;,</span>
<span class="sd">            )</span>
<span class="sd">            idf = IntervalsDF(df, &quot;start_ts&quot;, &quot;end_ts&quot;, [&quot;series_1&quot;], [&quot;metric_1&quot;, &quot;metric_2&quot;])</span>
<span class="sd">            idf.df.collect()</span>
<span class="sd">            [Row(start_ts=&#39;2020-08-01 00:00:09&#39;, end_ts=&#39;2020-08-01 00:00:14&#39;, series_1=&#39;v1&#39;, metric_1=5, metric_2=0)]</span>

<span class="sd">        .. _`DataFrame`: https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.html</span>

<span class="sd">        .. todo::</span>
<span class="sd">            - create IntervalsSchema class to validate data types and column</span>
<span class="sd">                existence</span>
<span class="sd">            - check elements of series and identifiers to ensure all are str</span>
<span class="sd">            - check if start_ts, end_ts, and the elements of series and</span>
<span class="sd">                identifiers can be of type col</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">start_ts</span> <span class="o">=</span> <span class="n">start_ts</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">end_ts</span> <span class="o">=</span> <span class="n">end_ts</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">series_ids</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">series_ids</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">series_ids</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">series_ids</span> <span class="o">=</span> <span class="n">series_ids</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;series_ids must be a list of column names, instead got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">series_ids</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

    <span class="nd">@cached_property</span>
    <span class="k">def</span> <span class="nf">interval_boundaries</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">start_ts</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">end_ts</span><span class="p">]</span>

    <span class="nd">@cached_property</span>
    <span class="k">def</span> <span class="nf">structural_columns</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">interval_boundaries</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">series_ids</span>

    <span class="nd">@cached_property</span>
    <span class="k">def</span> <span class="nf">observational_columns</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">structural_columns</span><span class="p">))</span>

    <span class="nd">@cached_property</span>
    <span class="k">def</span> <span class="nf">metric_columns</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">col</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="o">.</span><span class="n">schema</span><span class="o">.</span><span class="n">fields</span> <span class="k">if</span> <span class="n">is_metric_col</span><span class="p">(</span><span class="n">col</span><span class="p">)]</span>

    <span class="nd">@cached_property</span>
    <span class="k">def</span> <span class="nf">window</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">Window</span><span class="o">.</span><span class="n">partitionBy</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">series_ids</span><span class="p">)</span><span class="o">.</span><span class="n">orderBy</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">interval_boundaries</span><span class="p">)</span>

<div class="viewcode-block" id="IntervalsDF.fromStackedMetrics"><a class="viewcode-back" href="../../reference/tempo.intervals.html#tempo.intervals.IntervalsDF.fromStackedMetrics">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">fromStackedMetrics</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">df</span><span class="p">:</span> <span class="n">DataFrame</span><span class="p">,</span>
        <span class="n">start_ts</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">end_ts</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">series</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">metrics_name_col</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">metrics_value_col</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">metric_names</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;IntervalsDF&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a new :class:`IntervalsDF` with metrics of the current DataFrame</span>
<span class="sd">        pivoted by start and end timestamp and series.</span>

<span class="sd">        There are two versions of `fromStackedMetrics`. One that requires the caller</span>
<span class="sd">        to specify the list of distinct metric names to pivot on, and one that does</span>
<span class="sd">        not. The latter is more concise but less efficient, because Spark needs to</span>
<span class="sd">        first compute the list of distinct metric names internally.</span>

<span class="sd">        :param df: :class:`DataFrame` to wrap with :class:`IntervalsDF`</span>
<span class="sd">        :type df: `DataFrame`_</span>
<span class="sd">        :param start_ts: Name of the column which denotes interval start</span>
<span class="sd">        :type start_ts: str</span>
<span class="sd">        :param end_ts: Name of the column which denotes interval end</span>
<span class="sd">        :type end_ts: str</span>
<span class="sd">        :param series: column names</span>
<span class="sd">        :type series: list[str]</span>
<span class="sd">        :param metrics_name_col: column name</span>
<span class="sd">        :type metrics_name_col: str</span>
<span class="sd">        :param metrics_value_col: column name</span>
<span class="sd">        :type metrics_value_col: str</span>
<span class="sd">        :param metric_names: List of metric names that will be translated to</span>
<span class="sd">            columns in the output :class:`IntervalsDF`.</span>
<span class="sd">        :type metric_names: list[str], optional</span>
<span class="sd">        :return: A new :class:`IntervalsDF` with a column and respective</span>
<span class="sd">            values per distinct metric in `metrics_name_col`.</span>

<span class="sd">        :Example:</span>

<span class="sd">        .. code-block::</span>

<span class="sd">            df = spark.createDataFrame(</span>
<span class="sd">                [[&quot;2020-08-01 00:00:09&quot;, &quot;2020-08-01 00:00:14&quot;, &quot;v1&quot;, &quot;metric_1&quot;, 5],</span>
<span class="sd">                 [&quot;2020-08-01 00:00:09&quot;, &quot;2020-08-01 00:00:11&quot;, &quot;v1&quot;, &quot;metric_2&quot;, 0]],</span>
<span class="sd">                &quot;start_ts STRING, end_ts STRING, series_1 STRING, metric_name STRING, metric_value INT&quot;,</span>
<span class="sd">            )</span>

<span class="sd">            # With distinct metric names specified</span>

<span class="sd">            idf = IntervalsDF.fromStackedMetrics(</span>
<span class="sd">                df, &quot;start_ts&quot;, &quot;end_ts&quot;, [&quot;series_1&quot;], &quot;metric_name&quot;, &quot;metric_value&quot;, [&quot;metric_1&quot;, &quot;metric_2&quot;],</span>
<span class="sd">            )</span>
<span class="sd">            idf.df.collect()</span>
<span class="sd">            [Row(start_ts=&#39;2020-08-01 00:00:09&#39;, end_ts=&#39;2020-08-01 00:00:14&#39;, series_1=&#39;v1&#39;, metric_1=5, metric_2=null),</span>
<span class="sd">             Row(start_ts=&#39;2020-08-01 00:00:09&#39;, end_ts=&#39;2020-08-01 00:00:11&#39;, series_1=&#39;v1&#39;, metric_1=null, metric_2=0)]</span>

<span class="sd">            # Or without specifying metric names (less efficient)</span>

<span class="sd">            idf = IntervalsDF.fromStackedMetrics(df, &quot;start_ts&quot;, &quot;end_ts&quot;, [&quot;series_1&quot;], &quot;metric_name&quot;, &quot;metric_value&quot;)</span>
<span class="sd">            idf.df.collect()</span>
<span class="sd">            [Row(start_ts=&#39;2020-08-01 00:00:09&#39;, end_ts=&#39;2020-08-01 00:00:14&#39;, series_1=&#39;v1&#39;, metric_1=5, metric_2=null),</span>
<span class="sd">             Row(start_ts=&#39;2020-08-01 00:00:09&#39;, end_ts=&#39;2020-08-01 00:00:11&#39;, series_1=&#39;v1&#39;, metric_1=null, metric_2=0)]</span>

<span class="sd">        .. _`DataFrame`: https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.html</span>

<span class="sd">        .. todo::</span>
<span class="sd">            - check elements of identifiers to ensure all are str</span>
<span class="sd">            - check if start_ts, end_ts, and the elements of series and</span>
<span class="sd">                identifiers can be of type col</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">series</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span>

        <span class="n">df</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">df</span><span class="o">.</span><span class="n">groupBy</span><span class="p">(</span><span class="n">start_ts</span><span class="p">,</span> <span class="n">end_ts</span><span class="p">,</span> <span class="o">*</span><span class="n">series</span><span class="p">)</span>
            <span class="o">.</span><span class="n">pivot</span><span class="p">(</span><span class="n">metrics_name_col</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="n">metric_names</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
            <span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">metrics_value_col</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">start_ts</span><span class="p">,</span> <span class="n">end_ts</span><span class="p">,</span> <span class="n">series</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">__get_adjacent_rows</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">df</span><span class="p">:</span> <span class="n">DataFrame</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataFrame</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a new `Spark DataFrame`_ containing columns from applying the</span>
<span class="sd">        `lead`_ and `lag`_ window functions.</span>

<span class="sd">        .. _`Spark DataFrame`: https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.html</span>
<span class="sd">        .. `lead`_: https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.lead.html#pyspark.sql.functions.lead</span>
<span class="sd">        .. `lag`_: https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.lag.html#pyspark.sql.functions.lag</span>

<span class="sd">        .. todo:</span>
<span class="sd">            - should column names generated here be created at class</span>
<span class="sd">                initialization, saved as attributes then iterated on here?</span>
<span class="sd">                this would allow easier reuse throughout code</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">interval_boundaries</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">metric_columns</span><span class="p">:</span>
            <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;_lead_1_</span><span class="si">{</span><span class="n">c</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="n">f</span><span class="o">.</span><span class="n">lead</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">over</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">window</span><span class="p">),</span>
            <span class="p">)</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;_lag_1_</span><span class="si">{</span><span class="n">c</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="n">f</span><span class="o">.</span><span class="n">lag</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">over</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">window</span><span class="p">),</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="n">df</span>

    <span class="k">def</span> <span class="nf">__identify_subset_intervals</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">df</span><span class="p">:</span> <span class="n">DataFrame</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">DataFrame</span><span class="p">,</span> <span class="nb">str</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a new `Spark DataFrame`_ containing a boolean column if the</span>
<span class="sd">        current interval is a subset of the previous interval and the name</span>
<span class="sd">        of this column for future use.</span>

<span class="sd">        .. _`Spark DataFrame`: https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.html</span>

<span class="sd">        .. todo:</span>
<span class="sd">            - should subset_indicator be defined here or as an attribute for</span>
<span class="sd">                easier reuse across code?</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">subset_indicator</span> <span class="o">=</span> <span class="s2">&quot;_lag_1_is_subset&quot;</span>

        <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span>
            <span class="n">subset_indicator</span><span class="p">,</span>
            <span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;_lag_1_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">start_ts</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">f</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">start_ts</span><span class="p">))</span>
            <span class="o">&amp;</span> <span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;_lag_1_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">end_ts</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">f</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">end_ts</span><span class="p">)),</span>
        <span class="p">)</span>

        <span class="c1"># NB: the first record cannot be a subset of the previous and</span>
        <span class="c1"># `lag` will return null for this record with no default set</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span>
            <span class="kc">False</span><span class="p">,</span>
            <span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="n">subset_indicator</span><span class="p">],</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">df</span><span class="p">,</span> <span class="n">subset_indicator</span>

    <span class="k">def</span> <span class="nf">__identify_overlaps</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">df</span><span class="p">:</span> <span class="n">DataFrame</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">DataFrame</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a new `Spark DataFrame`_ containing boolean columns if the</span>
<span class="sd">        current interval overlaps with the previous or next interval and a list</span>
<span class="sd">        with the names of these columns for future use.</span>

<span class="sd">        .. _`Spark DataFrame`: https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.html</span>

<span class="sd">        .. todo:</span>
<span class="sd">            - should overlap_indicators be defined here or as an attribute for</span>
<span class="sd">                easier reuse across code?</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">overlap_indicators</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># identify overlaps for each interval boundary</span>
        <span class="c1"># NB: between is inclusive so not used here, and</span>
        <span class="c1"># matches on boundaries should be ignored</span>
        <span class="k">for</span> <span class="n">ts</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">interval_boundaries</span><span class="p">:</span>
            <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;_lead_1_</span><span class="si">{</span><span class="n">ts</span><span class="si">}</span><span class="s2">_overlaps&quot;</span><span class="p">,</span>
                <span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;_lead_1_</span><span class="si">{</span><span class="n">ts</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">f</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">start_ts</span><span class="p">))</span>
                <span class="o">&amp;</span> <span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;_lead_1_</span><span class="si">{</span><span class="n">ts</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">f</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">end_ts</span><span class="p">)),</span>
            <span class="p">)</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;_lag_1_</span><span class="si">{</span><span class="n">ts</span><span class="si">}</span><span class="s2">_overlaps&quot;</span><span class="p">,</span>
                <span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;_lag_1_</span><span class="si">{</span><span class="n">ts</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">f</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">start_ts</span><span class="p">))</span>
                <span class="o">&amp;</span> <span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;_lag_1_</span><span class="si">{</span><span class="n">ts</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">f</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">end_ts</span><span class="p">)),</span>
            <span class="p">)</span>

            <span class="n">overlap_indicators</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span>
                <span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;_lead_1_</span><span class="si">{</span><span class="n">ts</span><span class="si">}</span><span class="s2">_overlaps&quot;</span><span class="p">,</span>
                    <span class="sa">f</span><span class="s2">&quot;_lag_1_</span><span class="si">{</span><span class="n">ts</span><span class="si">}</span><span class="s2">_overlaps&quot;</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>

        <span class="c1"># NB: the first and last record cannot be a subset of the previous and</span>
        <span class="c1"># next respectively. `lag` will return null for this record with no</span>
        <span class="c1"># default set.</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span>
            <span class="kc">False</span><span class="p">,</span>
            <span class="n">subset</span><span class="o">=</span><span class="n">overlap_indicators</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">df</span><span class="p">,</span> <span class="n">overlap_indicators</span>

    <span class="k">def</span> <span class="nf">__merge_adjacent_subset_and_superset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">df</span><span class="p">:</span> <span class="n">DataFrame</span><span class="p">,</span> <span class="n">subset_indicator</span><span class="p">:</span> <span class="nb">str</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataFrame</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a new `Spark DataFrame`_ where a subset and it&#39;s adjacent</span>
<span class="sd">        superset, identified by `subset_indicator` are merged together.</span>

<span class="sd">        We assume that a metric cannot simultaneously have two values in the</span>
<span class="sd">        same interval (unless captured in a structure such as ArrayType, etc)</span>
<span class="sd">        so `coalesce`_ is used to merge metrics when a subset exist. Priority</span>
<span class="sd">        in the coalesce is given to the metrics of the current record, ie it</span>
<span class="sd">        is listed as the first argument.</span>

<span class="sd">        .. _`Spark DataFrame`: https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.html</span>
<span class="sd">        .. _`coalesce`: https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.coalesce.html</span>

<span class="sd">        .. todo:</span>
<span class="sd">            - should subset_indicator be defined here or as an attribute for</span>
<span class="sd">                easier reuse across code?</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">metric_columns</span><span class="p">:</span>
            <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span>
                <span class="n">c</span><span class="p">,</span>
                <span class="n">f</span><span class="o">.</span><span class="n">when</span><span class="p">(</span>
                    <span class="n">f</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">subset_indicator</span><span class="p">),</span> <span class="n">f</span><span class="o">.</span><span class="n">coalesce</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">c</span><span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;_lag_1_</span><span class="si">{</span><span class="n">c</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="p">)</span><span class="o">.</span><span class="n">otherwise</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">c</span><span class="p">)),</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="n">df</span>

    <span class="k">def</span> <span class="nf">__merge_adjacent_overlaps</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">df</span><span class="p">:</span> <span class="n">DataFrame</span><span class="p">,</span> <span class="n">how</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">overlap_indicators</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataFrame</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a new `Spark DataFrame`_ where adjacent intervals which overlap,</span>
<span class="sd">        identified by `overlap_indicators` are merged together.</span>

<span class="sd">        We assume that a metric cannot simultaneously have two values in the</span>
<span class="sd">        same interval (unless captured in a structure such as ArrayType, etc)</span>
<span class="sd">        so `coalesce`_ is used to merge metrics when overlaps exist. Priority</span>
<span class="sd">        in the `coalesce` is given to the metrics of the current record, ie it</span>
<span class="sd">        is listed as the first argument.</span>

<span class="sd">        .. _`Spark DataFrame`: https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.html</span>
<span class="sd">        .. _`coalesce`: https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.coalesce.html</span>

<span class="sd">        .. todo:</span>
<span class="sd">            - should overlap_indicators be defined here or as an attribute for</span>
<span class="sd">                easier reuse across code?</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">how</span> <span class="o">==</span> <span class="s2">&quot;left&quot;</span><span class="p">:</span>

            <span class="c1"># new boundary for interval end will become the start of the next</span>
            <span class="c1"># interval</span>
            <span class="n">new_boundary_col</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">end_ts</span>
            <span class="n">new_boundary_val</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;_lead_1_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">start_ts</span><span class="si">}</span><span class="s2">&quot;</span>

        <span class="k">else</span><span class="p">:</span>

            <span class="c1"># new boundary for interval start will become the end of the</span>
            <span class="c1"># previous interval</span>
            <span class="n">new_boundary_col</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_ts</span>
            <span class="n">new_boundary_val</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;_lead_1_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">end_ts</span><span class="si">}</span><span class="s2">&quot;</span>

        <span class="c1"># NB: supersets are split here</span>
        <span class="c1"># subsets are filled with the superset metrics in</span>
        <span class="c1"># `__merge_adjacent_subset_and_superset`</span>
        <span class="n">superset_interval_when_case</span> <span class="o">=</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;WHEN _lead_1_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">start_ts</span><span class="si">}</span><span class="s2">_overlaps &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;AND _lead_1_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">end_ts</span><span class="si">}</span><span class="s2">_overlaps &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;THEN </span><span class="si">{</span><span class="n">new_boundary_val</span><span class="si">}</span><span class="s2"> &quot;</span>
        <span class="p">)</span>

        <span class="n">overlap_interval_when_cases</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;WHEN </span><span class="si">{</span><span class="n">c</span><span class="si">}</span><span class="s2"> THEN </span><span class="si">{</span><span class="n">c</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;_overlaps&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span><span class="si">}</span><span class="s2"> &quot;</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">overlap_indicators</span>
        <span class="p">)</span>

        <span class="c1"># this logic will be used to create boundaries of disjoint intervals</span>
        <span class="n">new_interval_boundaries</span> <span class="o">=</span> <span class="p">(</span>
            <span class="s2">&quot;CASE &quot;</span>
            <span class="o">+</span> <span class="n">superset_interval_when_case</span>
            <span class="o">+</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">overlap_interval_when_cases</span><span class="p">)</span>
            <span class="o">+</span> <span class="s2">&quot;ELSE null END &quot;</span>
        <span class="p">)</span>

        <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span>
            <span class="n">new_boundary_col</span><span class="p">,</span>
            <span class="n">f</span><span class="o">.</span><span class="n">expr</span><span class="p">(</span><span class="n">new_interval_boundaries</span><span class="p">),</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">how</span> <span class="o">==</span> <span class="s2">&quot;left&quot;</span><span class="p">:</span>

            <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">metric_columns</span><span class="p">:</span>
                <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span>
                    <span class="n">c</span><span class="p">,</span>
                    <span class="c1"># needed when intervals have same start but different ends</span>
                    <span class="c1"># in this case, merge metrics since they overlap</span>
                    <span class="n">f</span><span class="o">.</span><span class="n">when</span><span class="p">(</span>
                        <span class="n">f</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;_lag_1_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">end_ts</span><span class="si">}</span><span class="s2">_overlaps&quot;</span><span class="p">),</span>
                        <span class="n">f</span><span class="o">.</span><span class="n">coalesce</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">c</span><span class="p">),</span> <span class="n">f</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;_lag_1_</span><span class="si">{</span><span class="n">c</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)),</span>
                    <span class="p">)</span>
                    <span class="c1"># general case when constructing left disjoint interval</span>
                    <span class="c1"># just want new boundary without merging metrics</span>
                    <span class="o">.</span><span class="n">otherwise</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">c</span><span class="p">)),</span>
                <span class="p">)</span>

        <span class="k">return</span> <span class="n">df</span>

    <span class="k">def</span> <span class="nf">__merge_equal_intervals</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">df</span><span class="p">:</span> <span class="n">DataFrame</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataFrame</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a new `Spark DataFrame`_ where intervals with the same start</span>
<span class="sd">        and end timestamps are merged together.</span>

<span class="sd">        We assume that a metric cannot simultaneously have two values in the</span>
<span class="sd">        same interval (unless captured in a structure such as ArrayType, etc.)</span>
<span class="sd">        so `groupBy`_ with an arbitrary `aggregate function`_ is used to merge</span>
<span class="sd">        metrics when a subset exists. In this implementation, `max`_ is used to</span>
<span class="sd">        perform the merge.</span>

<span class="sd">        .. _`Spark DataFrame`: https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.html</span>
<span class="sd">        .. _`groupBy`: https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.groupBy.html</span>
<span class="sd">        .. _`aggregate function`: https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/functions.html#aggregate-functions</span>
<span class="sd">        .. _`max`: https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.max.html</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">merge_expr</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">c</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">metric_columns</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">df</span><span class="o">.</span><span class="n">groupBy</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">interval_boundaries</span><span class="p">,</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">series_ids</span><span class="p">)</span><span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="o">*</span><span class="n">merge_expr</span><span class="p">)</span>

<div class="viewcode-block" id="IntervalsDF.disjoint"><a class="viewcode-back" href="../../reference/tempo.intervals.html#tempo.intervals.IntervalsDF.disjoint">[docs]</a>    <span class="k">def</span> <span class="nf">disjoint</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;IntervalsDF&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a new :class:`IntervalsDF` where metrics of overlapping time intervals</span>
<span class="sd">        are correlated and merged prior to constructing new time interval boundaries (</span>
<span class="sd">        start and end timestamp) so that all intervals are disjoint.</span>

<span class="sd">        The merge process assumes that two overlapping intervals cannot simultaneously</span>
<span class="sd">        report two different values for the same metric unless recorded in a data type</span>
<span class="sd">        which supports multiple elements (such as ArrayType, etc.).</span>

<span class="sd">        This is often used after :meth:`fromStackedMetrics` to reduce the number of</span>
<span class="sd">        metrics with `null` values and helps when constructing filter predicates to</span>
<span class="sd">        to retrieve specific metric values across all instances.</span>

<span class="sd">        :return: A new :class:`IntervalsDF` containing disjoint time intervals</span>

<span class="sd">        :Example:</span>

<span class="sd">        .. code-block::</span>

<span class="sd">            df = spark.createDataFrame(</span>
<span class="sd">                [[&quot;2020-08-01 00:00:10&quot;, &quot;2020-08-01 00:00:14&quot;, &quot;v1&quot;, 5, null],</span>
<span class="sd">                 [&quot;2020-08-01 00:00:09&quot;, &quot;2020-08-01 00:00:11&quot;, &quot;v1&quot;, null, 0]],</span>
<span class="sd">                &quot;start_ts STRING, end_ts STRING, series_1 STRING, metric_1 STRING, metric_2 INT&quot;,</span>
<span class="sd">            )</span>
<span class="sd">            idf = IntervalsDF(df, &quot;start_ts&quot;, &quot;end_ts&quot;, [&quot;series_1&quot;], [&quot;metric_1&quot;, &quot;metric_2&quot;])</span>
<span class="sd">            idf.disjoint().df.collect()</span>
<span class="sd">            [Row(start_ts=&#39;2020-08-01 00:00:09&#39;, end_ts=&#39;2020-08-01 00:00:10&#39;, series_1=&#39;v1&#39;, metric_1=null, metric_2=0),</span>
<span class="sd">             Row(start_ts=&#39;2020-08-01 00:00:10&#39;, end_ts=&#39;2020-08-01 00:00:11&#39;, series_1=&#39;v1&#39;, metric_1=5, metric_2=0),</span>
<span class="sd">             Row(start_ts=&#39;2020-08-01 00:00:11&#39;, end_ts=&#39;2020-08-01 00:00:14&#39;, series_1=&#39;v1&#39;, metric_1=5, metric_2=null)]</span>

<span class="sd">        .. todo:</span>
<span class="sd">            - checks that when merging in helper functions, prior to coalesce at least</span>
<span class="sd">                one of the metrics is null</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">df</span>

        <span class="n">df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__get_adjacent_rows</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

        <span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">subset_indicator</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__identify_subset_intervals</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

        <span class="n">subset_df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">subset_indicator</span><span class="p">))</span>

        <span class="n">subset_df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__merge_adjacent_subset_and_superset</span><span class="p">(</span>
            <span class="n">subset_df</span><span class="p">,</span> <span class="n">subset_indicator</span>
        <span class="p">)</span>

        <span class="n">subset_df</span> <span class="o">=</span> <span class="n">subset_df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span>
            <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">interval_boundaries</span><span class="p">,</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">series_ids</span><span class="p">,</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">metric_columns</span>
        <span class="p">)</span>

        <span class="n">non_subset_df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="o">~</span><span class="n">f</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">subset_indicator</span><span class="p">))</span>

        <span class="p">(</span><span class="n">non_subset_df</span><span class="p">,</span> <span class="n">overlap_indicators</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__identify_overlaps</span><span class="p">(</span><span class="n">non_subset_df</span><span class="p">)</span>

        <span class="n">overlaps_predicate</span> <span class="o">=</span> <span class="s2">&quot; OR &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">col</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">overlap_indicators</span><span class="p">))</span>

        <span class="n">overlaps_df</span> <span class="o">=</span> <span class="n">non_subset_df</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">overlaps_predicate</span><span class="p">)</span>

        <span class="n">disjoint_predicate</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;NOT(</span><span class="si">{</span><span class="n">overlaps_predicate</span><span class="si">}</span><span class="s2">)&quot;</span>

        <span class="c1"># filter for intervals that are already disjoint</span>
        <span class="n">disjoint_df</span> <span class="o">=</span> <span class="n">non_subset_df</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">disjoint_predicate</span><span class="p">)</span><span class="o">.</span><span class="n">select</span><span class="p">(</span>
            <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">interval_boundaries</span><span class="p">,</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">series_ids</span><span class="p">,</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">metric_columns</span>
        <span class="p">)</span>

        <span class="n">left_overlaps_df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__merge_adjacent_overlaps</span><span class="p">(</span>
            <span class="n">overlaps_df</span><span class="p">,</span> <span class="s2">&quot;left&quot;</span><span class="p">,</span> <span class="n">overlap_indicators</span>
        <span class="p">)</span>

        <span class="n">left_overlaps_df</span> <span class="o">=</span> <span class="n">left_overlaps_df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span>
            <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">interval_boundaries</span><span class="p">,</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">series_ids</span><span class="p">,</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">metric_columns</span>
        <span class="p">)</span>

        <span class="n">right_overlaps_df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__merge_adjacent_overlaps</span><span class="p">(</span>
            <span class="n">overlaps_df</span><span class="p">,</span> <span class="s2">&quot;right&quot;</span><span class="p">,</span> <span class="n">overlap_indicators</span>
        <span class="p">)</span>

        <span class="n">right_overlaps_df</span> <span class="o">=</span> <span class="n">right_overlaps_df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span>
            <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">interval_boundaries</span><span class="p">,</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">series_ids</span><span class="p">,</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">metric_columns</span>
        <span class="p">)</span>

        <span class="n">unioned_df</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">subset_df</span><span class="o">.</span><span class="n">unionByName</span><span class="p">(</span><span class="n">disjoint_df</span><span class="p">)</span>
            <span class="o">.</span><span class="n">unionByName</span><span class="p">(</span><span class="n">left_overlaps_df</span><span class="p">)</span>
            <span class="o">.</span><span class="n">unionByName</span><span class="p">(</span><span class="n">right_overlaps_df</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="n">disjoint_df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__merge_equal_intervals</span><span class="p">(</span><span class="n">unioned_df</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">IntervalsDF</span><span class="p">(</span><span class="n">disjoint_df</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_ts</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">end_ts</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">series_ids</span><span class="p">)</span></div>

<div class="viewcode-block" id="IntervalsDF.union"><a class="viewcode-back" href="../../reference/tempo.intervals.html#tempo.intervals.IntervalsDF.union">[docs]</a>    <span class="k">def</span> <span class="nf">union</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="s2">&quot;IntervalsDF&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;IntervalsDF&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a new :class:`IntervalsDF` containing union of rows in this and another</span>
<span class="sd">        :class:`IntervalsDF`.</span>

<span class="sd">        This is equivalent to UNION ALL in SQL. To do a SQL-style set union</span>
<span class="sd">        (that does deduplication of elements), use this function followed by</span>
<span class="sd">        distinct().</span>

<span class="sd">        Also, as standard in SQL, this function resolves columns by position</span>
<span class="sd">        (not by name).</span>

<span class="sd">        Based on `pyspark.sql.DataFrame.union`_.</span>

<span class="sd">        :param other: :class:`IntervalsDF` to `union`</span>
<span class="sd">        :type other: :class:`IntervalsDF`</span>
<span class="sd">        :return: A new :class:`IntervalsDF` containing union of rows in this</span>
<span class="sd">            and `other`</span>

<span class="sd">        .. _`pyspark.sql.DataFrame.union`: https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.union.html</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="n">IntervalsDF</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span>

        <span class="k">return</span> <span class="n">IntervalsDF</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="n">other</span><span class="o">.</span><span class="n">df</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_ts</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">end_ts</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">series_ids</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="IntervalsDF.unionByName"><a class="viewcode-back" href="../../reference/tempo.intervals.html#tempo.intervals.IntervalsDF.unionByName">[docs]</a>    <span class="k">def</span> <span class="nf">unionByName</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="s2">&quot;IntervalsDF&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;IntervalsDF&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a new :class:`IntervalsDF` containing union of rows in this</span>
<span class="sd">        and another :class:`IntervalsDF`.</span>

<span class="sd">        This is different from both UNION ALL and UNION DISTINCT in SQL. To do</span>
<span class="sd">        a SQL-style set union (that does deduplication of elements), use this</span>
<span class="sd">        function followed by distinct().</span>

<span class="sd">        Based on `pyspark.sql.DataFrame.unionByName`_; however,</span>
<span class="sd">        `allowMissingColumns` is not supported.</span>

<span class="sd">        :param other: :class:`IntervalsDF` to `unionByName`</span>
<span class="sd">        :type other: :class:`IntervalsDF`</span>
<span class="sd">        :return: A new :class:`IntervalsDF` containing union of rows in this</span>
<span class="sd">            and `other`</span>

<span class="sd">        .. _`pyspark.sql.DataFrame.unionByName`: https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.unionByName.html</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="n">IntervalsDF</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span>

        <span class="k">return</span> <span class="n">IntervalsDF</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="o">.</span><span class="n">unionByName</span><span class="p">(</span><span class="n">other</span><span class="o">.</span><span class="n">df</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_ts</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">end_ts</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">series_ids</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="IntervalsDF.toDF"><a class="viewcode-back" href="../../reference/tempo.intervals.html#tempo.intervals.IntervalsDF.toDF">[docs]</a>    <span class="k">def</span> <span class="nf">toDF</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stack</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataFrame</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a new `Spark DataFrame`_ converted from :class:`IntervalsDF`.</span>

<span class="sd">        There are two versions of `toDF`. One that will output columns as they exist</span>
<span class="sd">        in :class:`IntervalsDF` and, one that will stack metric columns into</span>
<span class="sd">        `metric_names` and `metric_values` columns populated with their respective</span>
<span class="sd">        values. The latter can be thought of as the inverse of</span>
<span class="sd">        :meth:`fromStackedMetrics`.</span>

<span class="sd">        Based on `pyspark.sql.DataFrame.toDF`_.</span>

<span class="sd">        :param stack: How to handle metric columns in the conversion to a `DataFrame`</span>
<span class="sd">        :type stack: bool, optional</span>
<span class="sd">        :return:</span>

<span class="sd">        .. _`Spark DataFrame`: https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.html</span>
<span class="sd">        .. _`pyspark.sql.DataFrame.toDF`: https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.toDF.html</span>
<span class="sd">        .. _`STACK`: https://spark.apache.org/docs/latest/api/sql/index.html#stack</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">stack</span><span class="p">:</span>

            <span class="n">n_cols</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">metric_columns</span><span class="p">)</span>
            <span class="n">metric_cols_expr</span> <span class="o">=</span> <span class="s2">&quot;,&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
                <span class="nb">tuple</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&#39;</span><span class="si">{</span><span class="n">col</span><span class="si">}</span><span class="s2">&#39;, </span><span class="si">{</span><span class="n">col</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">metric_columns</span><span class="p">)</span>
            <span class="p">)</span>

            <span class="n">stack_expr</span> <span class="o">=</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;STACK(</span><span class="si">{</span><span class="n">n_cols</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">metric_cols_expr</span><span class="si">}</span><span class="s2">) AS (metric_name, metric_value)&quot;</span>
            <span class="p">)</span>

            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span>
                <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">interval_boundaries</span><span class="p">,</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">series_ids</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">expr</span><span class="p">(</span><span class="n">stack_expr</span><span class="p">)</span>
            <span class="p">)</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="s2">&quot;metric_value&quot;</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">df</span></div></div>
</pre></div>
        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          
          
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2022, Databricks Labs
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            <div class="icons">
              <a class="muted-link " href="https://github.com/databrickslabs/tempo" aria-label="GitHub">
                <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16">
                    <path fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0 0 16 8c0-4.42-3.58-8-8-8z"></path>
                </svg>
            </a>
              <a class="muted-link fa-brands fa-uncharted" href="https://databricks.com/learn/labs" aria-label="Databricks Labs"></a>
              
            </div>
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer no-toc">
      
      
      
    </aside>
  </div>
</div><script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/scripts/furo.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    </body>
</html>